{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from least_squares import *\n",
    "from gradient_descent import *\n",
    "from stochastic_gradient_descent import *\n",
    "from ridge_regression import *\n",
    "from logistic_regression import *\n",
    "from newton import *\n",
    "from cross_validation import *\n",
    "\n",
    "from helpers import *\n",
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train.csv' \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tx, mean, std = standardize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000, 30), (250000, 31))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, x_test, id_test = load_csv_data('data/test.csv')\n",
    "tx_test, mean_test, std_test = standardize(x_test)\n",
    "tx_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares: loss*=0.3394455984940183, w0*=-0.31466399999964345, w1*=0.02937894984909547\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "ls_loss, ls_w = least_squares(y, tx)\n",
    "\n",
    "ls_w0 = ls_w[0]\n",
    "ls_w1 = ls_w[1]\n",
    "\n",
    "print(\"Least Squares: loss*={l}, w0*={w0}, w1*={w1}\".format(\n",
    "        l=ls_loss, w0=ls_w0, w1=ls_w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186243"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "ls_y_check = predict_labels(ls_w, tx)\n",
    "sum(ls_y_check == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict 0.74760\n",
    "LS_OUTPUT_PATH = 'data/ls_submission.csv'\n",
    "ls_y_pred = predict_labels(ls_w, tx_test)\n",
    "create_csv_submission(id_test, ls_y_pred, LS_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/299): loss=0.5, w0=-0.0471996, w1=0.03405015486157466\n",
      "Gradient Descent(10/299): loss=0.3649841296757523, w0=-0.2620071055676516, w1=0.0812202751318934\n",
      "Gradient Descent(20/299): loss=0.3550763049590692, w0=-0.30429720527420195, w1=0.06898193617063272\n",
      "Gradient Descent(30/299): loss=0.35048628668581794, w0=-0.3126230434634405, w1=0.058971823442580486\n",
      "Gradient Descent(40/299): loss=0.3474756325054262, w0=-0.3142621878975853, w1=0.05202445848547232\n",
      "Gradient Descent(50/299): loss=0.34539464652489404, w0=-0.3145848934816871, w1=0.047082545929858804\n",
      "Gradient Descent(60/299): loss=0.34392784649434605, w0=-0.3146484259513354, w1=0.04342652316324255\n",
      "Gradient Descent(70/299): loss=0.3428808998038696, w0=-0.31466093386845445, w1=0.04063318268296978\n",
      "Gradient Descent(80/299): loss=0.3421265445364248, w0=-0.31466339635718743, w1=0.03844935235840481\n",
      "Gradient Descent(90/299): loss=0.3415788792923234, w0=-0.31466388115819044, w1=0.036715290258110135\n",
      "Gradient Descent(100/299): loss=0.34117875601595093, w0=-0.3146639766030996, w1=0.03532402868906609\n",
      "Gradient Descent(110/299): loss=0.34088484893237536, w0=-0.31466399539375955, w1=0.03420000138802685\n",
      "Gradient Descent(120/299): loss=0.34066795241141284, w0=-0.31466399909315984, w1=0.03328749373807797\n",
      "Gradient Descent(130/299): loss=0.340507232033274, w0=-0.3146639998214773, w1=0.03254411375251265\n",
      "Gradient Descent(140/299): loss=0.34038770684636865, w0=-0.3146639999648646, w1=0.03193689089981834\n",
      "Gradient Descent(150/299): loss=0.34029853079729755, w0=-0.3146639999930941, w1=0.03143980057489527\n",
      "Gradient Descent(160/299): loss=0.3402318042960907, w0=-0.3146639999986519, w1=0.031032098534530837\n",
      "Gradient Descent(170/299): loss=0.34018174339264773, w0=-0.3146639999997462, w1=0.030697141343885074\n",
      "Gradient Descent(180/299): loss=0.34014409346988855, w0=-0.3146639999999618, w1=0.03042151621225894\n",
      "Gradient Descent(190/299): loss=0.3401157120404586, w0=-0.31466400000000433, w1=0.030194379486615935\n",
      "Gradient Descent(200/299): loss=0.3400942696603954, w0=-0.3146640000000128, w1=0.030006943182797546\n",
      "Gradient Descent(210/299): loss=0.3400780340822491, w0=-0.3146640000000145, w1=0.02985207087002391\n",
      "Gradient Descent(220/299): loss=0.34006571354290227, w0=-0.3146640000000149, w1=0.029723956759731697\n",
      "Gradient Descent(230/299): loss=0.340056342371075, w0=-0.31466400000001493, w1=0.029617869405747947\n",
      "Gradient Descent(240/299): loss=0.34004919708407205, w0=-0.314664000000015, w1=0.02952994625325605\n",
      "Gradient Descent(250/299): loss=0.3400437345842937, w0=-0.31466400000001504, w1=0.029457028546607585\n",
      "Gradient Descent(260/299): loss=0.34003954646254114, w0=-0.31466400000001504, w1=0.02939652843923889\n",
      "Gradient Descent(270/299): loss=0.3400363250981718, w0=-0.3146640000000151, w1=0.029346321880856223\n",
      "Gradient Descent(280/299): loss=0.34003383843738055, w0=-0.3146640000000151, w1=0.029304662180616895\n",
      "Gradient Descent(290/299): loss=0.3400319111802058, w0=-0.31466400000001515, w1=0.029270110176519353\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "max_iters = 300\n",
    "gamma = 0.15\n",
    "gd_loss, gd_w = gradient_descent(y, tx, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "# No need to generate predict file\n",
    "# GD is strictly worse than LS if no data filtering or feature weights are implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: lambda=0.000000, loss*=0.31786522157389413, w0*=-59626.77200386367, w1*=0.00012348494288154849\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "rr_lambdas = np.array([8e-15])\n",
    "degree = 2\n",
    "\n",
    "rr_phi = build_poly(x, degree)\n",
    "\n",
    "for lamb in rr_lambdas:\n",
    "    rr_loss, rr_w = ridge_regression(y, rr_phi, lamb)\n",
    "    rr_w0 = rr_w[0]\n",
    "    rr_w1 = rr_w[1]\n",
    "    print(\"Ridge Regression: lambda={lam:3f}, loss*={l}, w0*={w0}, w1*={w1}\".format(\n",
    "        lam=lamb, l=rr_loss, w0=rr_w0, w1=rr_w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192591"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "rr_x_check = build_poly(x, degree)\n",
    "rr_y_check = predict_labels(rr_w, rr_x_check)\n",
    "sum(rr_y_check == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict 0.76996\n",
    "rr_test_phi = build_poly(x_test, degree)\n",
    "rr_y_pred = predict_labels(rr_w, rr_test_phi)\n",
    "RR_OUTPUT_PATH = 'data/rr_submission.csv'\n",
    "create_csv_submission(id_test, rr_y_pred, RR_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "seed = 1\n",
    "k_fold = 10\n",
    "lamb = 8e-15\n",
    "degree = 2\n",
    "\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "# define lists to store the loss of training data and test data\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "weight_tr = 0\n",
    "\n",
    "for k in range(k_fold):\n",
    "    l_tr, l_te, w_tr = cross_validation(y, x, k_indices, k, lamb, degree)\n",
    "    loss_tr.append(l_tr)\n",
    "    loss_te.append(l_te)\n",
    "    weight_tr += w_tr\n",
    "    \n",
    "rcv_w = weight_tr / k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192651"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "rcv_x_check = build_poly(x, degree)\n",
    "rcv_y_check = predict_labels(rcv_w, rcv_x_check)\n",
    "sum(rcv_y_check == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict 0.77010\n",
    "rcv_test_phi = build_poly(x_test, degree)\n",
    "rcv_y_pred = predict_labels(rcv_w, rcv_test_phi)\n",
    "RCV_OUTPUT_PATH = 'data/rcv_submission.csv'\n",
    "create_csv_submission(id_test, rcv_y_pred, RCV_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the (-1, 1) classification problem into (0, 1)\n",
    "log_y = y.copy()\n",
    "for i in range(len(log_y)):\n",
    "    if log_y[i] == -1:\n",
    "        log_y[i] = 0\n",
    "        \n",
    "log_y[:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression with GD(0/199): loss=5.251673835930225, w0=0.9820152363517101, w1=1.000917742730888\n",
      "logistic regression with GD(10/199): loss=2.2464721097614415, w0=0.7008801683495484, w1=0.973306923063839\n",
      "logistic regression with GD(20/199): loss=1.1385378968121571, w0=0.22506262004311559, w1=0.8681563954008141\n",
      "logistic regression with GD(30/199): loss=0.7881992718141739, w0=-0.18323352984869065, w1=0.7414252132235548\n",
      "logistic regression with GD(40/199): loss=0.6275812378110788, w0=-0.45832495764845205, w1=0.6276787651478991\n",
      "logistic regression with GD(50/199): loss=0.5643941109355801, w0=-0.6232198981951527, w1=0.5497686454509927\n",
      "logistic regression with GD(60/199): loss=0.5388019607990212, w0=-0.7184900091077283, w1=0.5001154985611691\n",
      "logistic regression with GD(70/199): loss=0.527196103172945, w0=-0.7740306692828949, w1=0.46678497989916806\n",
      "logistic regression with GD(80/199): loss=0.5211854177245719, w0=-0.8073551774810406, w1=0.4423275245940156\n",
      "logistic regression with GD(90/199): loss=0.5176427389855227, w0=-0.8280898444490751, w1=0.4228254950739917\n",
      "logistic regression with GD(100/199): loss=0.5153027513325052, w0=-0.8414824465963554, w1=0.4063090816245113\n",
      "logistic regression with GD(110/199): loss=0.5136059723916181, w0=-0.8504396685418367, w1=0.3917907262138913\n",
      "logistic regression with GD(120/199): loss=0.51228340499169, w0=-0.8566177285600348, w1=0.3787637931650074\n",
      "logistic regression with GD(130/199): loss=0.5111958203061211, w0=-0.8609939887050908, w1=0.3669545642991847\n",
      "logistic regression with GD(140/199): loss=0.5102664086305831, w0=-0.8641675334271982, w1=0.3562013931484584\n",
      "logistic regression with GD(150/199): loss=0.509450338008947, w0=-0.866519676997236, w1=0.346396251991332\n",
      "logistic regression with GD(160/199): loss=0.508720048520894, w0=-0.8683016609986915, w1=0.3374567458501108\n",
      "logistic regression with GD(170/199): loss=0.5080577399422593, w0=-0.869683966700975, w1=0.32931297930110337\n",
      "logistic regression with GD(180/199): loss=0.5074513529380279, w0=-0.8707849892038203, w1=0.32190162642261744\n",
      "logistic regression with GD(190/199): loss=0.5068923347063533, w0=-0.8716883411971668, w1=0.3151634438536845\n"
     ]
    }
   ],
   "source": [
    "max_iters = 200\n",
    "gamma = 1e-6\n",
    "\n",
    "log_loss, log_w = logistic_regression(log_y, tx, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180164"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "log_y_train = predict_logistic_labels(log_w, tx)\n",
    "sum(log_y_train == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict 0.72849\n",
    "LOG_OUTPUT_PATH = 'data/log_submission.csv'\n",
    "log_y_pred = predict_logistic_labels(log_w, tx_test)\n",
    "create_csv_submission(id_test, log_y_pred, LOG_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with Newton method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_y = y.copy()\n",
    "for i in range(len(nt_y)):\n",
    "    if nt_y[i] == -1:\n",
    "        nt_y[i] = 0\n",
    "        \n",
    "nt_y[:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression with Newton(0/4): loss=5.251673835930225, w0=0.8694523517477522, w1=0.9999391698936346\n",
      "logistic regression with Newton(1/4): loss=5.16994722901324, w0=0.790285808782625, w1=0.9998791203845311\n",
      "logistic regression with Newton(2/4): loss=5.1222550873283055, w0=0.7292318748242601, w1=0.9998196343266107\n",
      "logistic regression with Newton(3/4): loss=5.085943382542923, w0=0.6792816984810927, w1=0.9997605954004771\n",
      "logistic regression with Newton(4/4): loss=5.056448324915354, w0=0.637075214983694, w1=0.9997019250261237\n"
     ]
    }
   ],
   "source": [
    "max_iters = 5\n",
    "gamma = 1e-6\n",
    "\n",
    "# DON'T RUN! COMPUTING COST IS TOO HIGH. WILL KILL KERNEL!\n",
    "nt_loss, nt_w = newton_method(log_y, tx, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-aa8eb25af8b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdiagb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiaga\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdiagb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Ismail\\Anaconda3\\lib\\site-packages\\numpy\\lib\\twodim_base.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_w = np.array([1.0] * tx.shape[1])\n",
    "grad = compute_logistic_gradient(nt_y, tx, initial_w)\n",
    "diaga = sigma(tx.dot(initial_w))\n",
    "diagb = 1 - sigma(tx.dot(initial_w))\n",
    "diag = diaga * diagb\n",
    "s = np.diag(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
