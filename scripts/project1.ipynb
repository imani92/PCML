{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from least_squares import *\n",
    "from gradient_descent import *\n",
    "from stochastic_gradient_descent import *\n",
    "from ridge_regression import *\n",
    "from logistic_regression import *\n",
    "from newton import *\n",
    "from cross_validation import *\n",
    "\n",
    "from helpers import *\n",
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train.csv' \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tx, mean, std = standardize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000, 30), (250000, 31))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, x_test, id_test = load_csv_data('data/test.csv')\n",
    "tx_test, mean_test, std_test = standardize(x_test)\n",
    "tx_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares: loss*=0.3394455984940183, w0*=-0.31466399999964345, w1*=0.02937894984909547\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "ls_loss, ls_w = least_squares(y, tx)\n",
    "\n",
    "ls_w0 = ls_w[0]\n",
    "ls_w1 = ls_w[1]\n",
    "\n",
    "print(\"Least Squares: loss*={l}, w0*={w0}, w1*={w1}\".format(\n",
    "        l=ls_loss, w0=ls_w0, w1=ls_w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186243"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "ls_y_check = predict_labels(ls_w, tx)\n",
    "sum(ls_y_check == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict 0.74760\n",
    "LS_OUTPUT_PATH = 'data/ls_submission.csv'\n",
    "ls_y_pred = predict_labels(ls_w, tx_test)\n",
    "create_csv_submission(id_test, ls_y_pred, LS_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/299): loss=0.5, w0=-0.0471996, w1=0.03405015486157466\n",
      "Gradient Descent(10/299): loss=0.3649841296757523, w0=-0.2620071055676516, w1=0.0812202751318934\n",
      "Gradient Descent(20/299): loss=0.3550763049590692, w0=-0.30429720527420195, w1=0.06898193617063272\n",
      "Gradient Descent(30/299): loss=0.35048628668581794, w0=-0.3126230434634405, w1=0.058971823442580486\n",
      "Gradient Descent(40/299): loss=0.3474756325054262, w0=-0.3142621878975853, w1=0.05202445848547232\n",
      "Gradient Descent(50/299): loss=0.34539464652489404, w0=-0.3145848934816871, w1=0.047082545929858804\n",
      "Gradient Descent(60/299): loss=0.34392784649434605, w0=-0.3146484259513354, w1=0.04342652316324255\n",
      "Gradient Descent(70/299): loss=0.3428808998038696, w0=-0.31466093386845445, w1=0.04063318268296978\n",
      "Gradient Descent(80/299): loss=0.3421265445364248, w0=-0.31466339635718743, w1=0.03844935235840481\n",
      "Gradient Descent(90/299): loss=0.3415788792923234, w0=-0.31466388115819044, w1=0.036715290258110135\n",
      "Gradient Descent(100/299): loss=0.34117875601595093, w0=-0.3146639766030996, w1=0.03532402868906609\n",
      "Gradient Descent(110/299): loss=0.34088484893237536, w0=-0.31466399539375955, w1=0.03420000138802685\n",
      "Gradient Descent(120/299): loss=0.34066795241141284, w0=-0.31466399909315984, w1=0.03328749373807797\n",
      "Gradient Descent(130/299): loss=0.340507232033274, w0=-0.3146639998214773, w1=0.03254411375251265\n",
      "Gradient Descent(140/299): loss=0.34038770684636865, w0=-0.3146639999648646, w1=0.03193689089981834\n",
      "Gradient Descent(150/299): loss=0.34029853079729755, w0=-0.3146639999930941, w1=0.03143980057489527\n",
      "Gradient Descent(160/299): loss=0.3402318042960907, w0=-0.3146639999986519, w1=0.031032098534530837\n",
      "Gradient Descent(170/299): loss=0.34018174339264773, w0=-0.3146639999997462, w1=0.030697141343885074\n",
      "Gradient Descent(180/299): loss=0.34014409346988855, w0=-0.3146639999999618, w1=0.03042151621225894\n",
      "Gradient Descent(190/299): loss=0.3401157120404586, w0=-0.31466400000000433, w1=0.030194379486615935\n",
      "Gradient Descent(200/299): loss=0.3400942696603954, w0=-0.3146640000000128, w1=0.030006943182797546\n",
      "Gradient Descent(210/299): loss=0.3400780340822491, w0=-0.3146640000000145, w1=0.02985207087002391\n",
      "Gradient Descent(220/299): loss=0.34006571354290227, w0=-0.3146640000000149, w1=0.029723956759731697\n",
      "Gradient Descent(230/299): loss=0.340056342371075, w0=-0.31466400000001493, w1=0.029617869405747947\n",
      "Gradient Descent(240/299): loss=0.34004919708407205, w0=-0.314664000000015, w1=0.02952994625325605\n",
      "Gradient Descent(250/299): loss=0.3400437345842937, w0=-0.31466400000001504, w1=0.029457028546607585\n",
      "Gradient Descent(260/299): loss=0.34003954646254114, w0=-0.31466400000001504, w1=0.02939652843923889\n",
      "Gradient Descent(270/299): loss=0.3400363250981718, w0=-0.3146640000000151, w1=0.029346321880856223\n",
      "Gradient Descent(280/299): loss=0.34003383843738055, w0=-0.3146640000000151, w1=0.029304662180616895\n",
      "Gradient Descent(290/299): loss=0.3400319111802058, w0=-0.31466400000001515, w1=0.029270110176519353\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "max_iters = 300\n",
    "gamma = 0.15\n",
    "gd_loss, gd_w = gradient_descent(y, tx, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "# No need to generate predict file\n",
    "# GD is strictly worse than LS if no data filtering or feature weights are implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: lambda=0.000000, loss*=0.31786522157389413, w0*=-59626.77200386367, w1*=0.00012348494288154849\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "rr_lambdas = np.array([8e-15])\n",
    "degree = 2\n",
    "\n",
    "rr_phi = build_poly(x, degree)\n",
    "\n",
    "for lamb in rr_lambdas:\n",
    "    rr_loss, rr_w = ridge_regression(y, rr_phi, lamb)\n",
    "    rr_w0 = rr_w[0]\n",
    "    rr_w1 = rr_w[1]\n",
    "    print(\"Ridge Regression: lambda={lam:3f}, loss*={l}, w0*={w0}, w1*={w1}\".format(\n",
    "        lam=lamb, l=rr_loss, w0=rr_w0, w1=rr_w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192591"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "rr_x_check = build_poly(x, degree)\n",
    "rr_y_check = predict_labels(rr_w, rr_x_check)\n",
    "sum(rr_y_check == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict 0.76996\n",
    "rr_test_phi = build_poly(x_test, degree)\n",
    "rr_y_pred = predict_labels(rr_w, rr_test_phi)\n",
    "RR_OUTPUT_PATH = 'data/rr_submission.csv'\n",
    "create_csv_submission(id_test, rr_y_pred, RR_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "seed = 1\n",
    "k_fold = 10\n",
    "lamb = 8e-15\n",
    "degree = 2\n",
    "\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "# define lists to store the loss of training data and test data\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "weight_tr = 0\n",
    "\n",
    "for k in range(k_fold):\n",
    "    l_tr, l_te, w_tr = cross_validation(y, x, k_indices, k, lamb, degree)\n",
    "    loss_tr.append(l_tr)\n",
    "    loss_te.append(l_te)\n",
    "    weight_tr += w_tr\n",
    "    \n",
    "rcv_w = weight_tr / k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192651"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "rcv_x_check = build_poly(x, degree)\n",
    "rcv_y_check = predict_labels(rcv_w, rcv_x_check)\n",
    "sum(rcv_y_check == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict 0.77010\n",
    "rcv_test_phi = build_poly(x_test, degree)\n",
    "rcv_y_pred = predict_labels(rcv_w, rcv_test_phi)\n",
    "RCV_OUTPUT_PATH = 'data/rcv_submission.csv'\n",
    "create_csv_submission(id_test, rcv_y_pred, RCV_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the (-1, 1) classification problem into (0, 1)\n",
    "log_y = y.copy()\n",
    "for i in range(len(log_y)):\n",
    "    if log_y[i] == -1:\n",
    "        log_y[i] = 0\n",
    "        \n",
    "log_y[:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression with GD(0/299): loss=2.682837515207593, w0=0.4792886650862448, w1=0.5007768283788979\n",
      "logistic regression with GD(20/299): loss=0.616510027467686, w0=-0.26331699128599506, w1=0.40816506142346515\n",
      "logistic regression with GD(40/299): loss=0.5363931283545257, w0=-0.6044983635043047, w1=0.35009208349049126\n",
      "logistic regression with GD(60/299): loss=0.5227242801507874, w0=-0.7353249119065798, w1=0.33364478788152807\n",
      "logistic regression with GD(80/299): loss=0.5174966086324174, w0=-0.7939061989167525, w1=0.3246734252858627\n",
      "logistic regression with GD(100/299): loss=0.5143808703287661, w0=-0.8235871357260085, w1=0.3166407784012507\n",
      "logistic regression with GD(120/299): loss=0.5121055242239606, w0=-0.8400849139099502, w1=0.3088243175380369\n",
      "logistic regression with GD(140/299): loss=0.5102904050169369, w0=-0.8499670399130937, w1=0.3014324525381244\n",
      "logistic regression with GD(160/299): loss=0.5087807188227276, w0=-0.8563078533973341, w1=0.29468723527678725\n",
      "logistic regression with GD(180/299): loss=0.5074975106456331, w0=-0.8606768246030241, w1=0.2886848285584795\n",
      "logistic regression with GD(200/299): loss=0.5063929097516581, w0=-0.8639199392219875, w1=0.2834212846395818\n",
      "logistic regression with GD(220/299): loss=0.505434053331826, w0=-0.8665055014867507, w1=0.2788384463518237\n",
      "logistic regression with GD(240/299): loss=0.5045965665253925, w0=-0.8686958566346114, w1=0.27485584536481567\n",
      "logistic regression with GD(260/299): loss=0.5038615129323749, w0=-0.8706387152327109, w1=0.2713887250979299\n",
      "logistic regression with GD(280/299): loss=0.503213750001644, w0=-0.8724173885599956, w1=0.2683571863479656\n"
     ]
    }
   ],
   "source": [
    "max_iters = 300\n",
    "gamma = 1e-6\n",
    "\n",
    "log_loss, log_w = logistic_regression(log_y, tx, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180533"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "log_y_train = predict_logistic_labels(log_w, tx)\n",
    "sum(log_y_train == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict 0.72849\n",
    "LOG_OUTPUT_PATH = 'data/log_submission.csv'\n",
    "log_y_pred = predict_logistic_labels(log_w, tx_test)\n",
    "create_csv_submission(id_test, log_y_pred, LOG_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logisticalization\n",
    "reg_y = y.copy()\n",
    "for i in range(len(reg_y)):\n",
    "    if reg_y[i] == -1:\n",
    "        reg_y[i] = 0\n",
    "        \n",
    "reg_y[:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression with GD(0/299): loss=2.682837515207593, w0=0.47927866508624484, w1=0.5007668283788979\n",
      "logistic regression with GD(20/299): loss=0.6164594109036251, w0=-0.2633436864032931, w1=0.4080176433706233\n",
      "logistic regression with GD(40/299): loss=0.5363948889402543, w0=-0.6043458056205644, w1=0.34990603938341813\n",
      "logistic regression with GD(60/299): loss=0.5227374563936514, w0=-0.7350279707320829, w1=0.33341832163501584\n",
      "logistic regression with GD(80/299): loss=0.5175140525579578, w0=-0.793503447021783, w1=0.32440879592875677\n",
      "logistic regression with GD(100/299): loss=0.5144011575215567, w0=-0.8231058494265406, w1=0.31634699360386176\n",
      "logistic regression with GD(120/299): loss=0.5121283884441394, w0=-0.8395445316432651, w1=0.3085116005782197\n",
      "logistic regression with GD(140/299): loss=0.5103158021464339, w0=-0.849381615628723, w1=0.3011097897572627\n",
      "logistic regression with GD(160/299): loss=0.5088085881819281, w0=-0.8556873466936473, w1=0.294361752929418\n",
      "logistic regression with GD(180/299): loss=0.5075277306198921, w0=-0.8600280579162946, w1=0.28836189518115624\n",
      "logistic regression with GD(200/299): loss=0.5064253133486116, w0=-0.8632474717246469, w1=0.2831047303003242\n",
      "logistic regression with GD(220/299): loss=0.5054684484183706, w0=-0.8658123066317787, w1=0.2785308500803016\n",
      "logistic regression with GD(240/299): loss=0.5046327507092884, w0=-0.86798381773527, w1=0.27455883894650085\n",
      "logistic regression with GD(260/299): loss=0.5038992832534657, w0=-0.8699089849666539, w1=0.27110326127995715\n",
      "logistic regression with GD(280/299): loss=0.5032529088111566, w0=-0.8716706450038411, w1=0.2680837519957619\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "max_iters = 300\n",
    "gamma = 1e-6\n",
    "lamb = 10\n",
    "\n",
    "reg_loss, reg_w = logistic_regression(reg_y, tx, max_iters, gamma, regularized=True, lambda_=lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180525"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "reg_y_train = predict_logistic_labels(reg_w, tx)\n",
    "sum(reg_y_train == y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "REG_OUTPUT_PATH = 'data/reg_submission.csv'\n",
    "reg_y_pred = predict_logistic_labels(reg_w, tx_test)\n",
    "create_csv_submission(id_test, reg_y_pred, REG_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with Newton method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_y = y.copy()\n",
    "for i in range(len(nt_y)):\n",
    "    if nt_y[i] == -1:\n",
    "        nt_y[i] = 0\n",
    "        \n",
    "nt_y[:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic with Newton(0/999): loss=2.737002412413841, w0=-1.7181550200522229, w1=0.44802379524322206\n",
      "logistic with Newton(50/999): loss=0.6228125940984359, w0=-0.9049012751400399, w1=0.23052569657523556\n",
      "logistic with Newton(100/999): loss=0.5467339034684046, w0=-0.838494723154859, w1=0.21739184709948728\n",
      "logistic with Newton(150/999): loss=0.5190068124265335, w0=-0.8366759109704975, w1=0.21330372558586713\n",
      "logistic with Newton(200/999): loss=0.5032983304543842, w0=-0.8514850303479574, w1=0.21514267436104093\n",
      "logistic with Newton(250/999): loss=0.4968322585801632, w0=-0.8675866737267524, w1=0.21782875518396022\n",
      "logistic with Newton(300/999): loss=0.4963691684124786, w0=-0.8796742269076965, w1=0.21899354200223928\n",
      "logistic with Newton(350/999): loss=0.5076311803961472, w0=-0.8918754092639407, w1=0.22417528404527762\n",
      "logistic with Newton(400/999): loss=0.49828422563838365, w0=-0.898974643138658, w1=0.22128517619590768\n",
      "logistic with Newton(450/999): loss=0.5004126275011205, w0=-0.9037515613346028, w1=0.22200909980391506\n",
      "logistic with Newton(500/999): loss=0.4963632553843709, w0=-0.9075520201798264, w1=0.2243025939341886\n",
      "logistic with Newton(550/999): loss=0.4955560239814541, w0=-0.9092351039303427, w1=0.2248931717339409\n",
      "logistic with Newton(600/999): loss=0.49160313953217755, w0=-0.9100273363147804, w1=0.22281968903156554\n",
      "logistic with Newton(650/999): loss=0.4992302986265663, w0=-0.9087208777015136, w1=0.22099034178947474\n",
      "logistic with Newton(700/999): loss=0.504645826582857, w0=-0.9098457223409425, w1=0.21703747036618234\n",
      "logistic with Newton(750/999): loss=0.5096090901627748, w0=-0.9099744674203866, w1=0.2174908157018689\n",
      "logistic with Newton(800/999): loss=0.49500548190889637, w0=-0.9099061423942693, w1=0.22258313705941515\n",
      "logistic with Newton(850/999): loss=0.5063202139766051, w0=-0.911489300729712, w1=0.2159193477814717\n",
      "logistic with Newton(900/999): loss=0.5007712420901342, w0=-0.9083326411942046, w1=0.21857228770698928\n",
      "logistic with Newton(950/999): loss=0.4938144043981797, w0=-0.9069167561015923, w1=0.2168279124173661\n"
     ]
    }
   ],
   "source": [
    "max_iters = 1000\n",
    "gamma = 1e-2\n",
    "batch_size = 10000\n",
    "lamb = 1\n",
    "\n",
    "nt_loss, nt_w = newton_method(nt_y, tx, batch_size, max_iters, gamma, regularized=True, lambda_=lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181964"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self check\n",
    "nt_y_train = predict_logistic_labels(nt_w, tx)\n",
    "sum(nt_y_train == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
